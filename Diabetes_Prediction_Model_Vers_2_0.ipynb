{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmosNjeruh/diabetes-ml-project-Ver2.0/blob/main/Diabetes_Prediction_Model_Vers_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-xsOEx6Px4Hy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "5414f39e-1722-4e45-b631-bba76c766de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6cfc9c413fb054f250.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6cfc9c413fb054f250.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "import tempfile\n",
        "%pip install -qq lime --disable-pip-version-check --no-input --no-color > NUL 2>&1\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import gradio as gr\n",
        "\n",
        "import shap\n",
        "import lime.lime_tabular\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import logging\n",
        "import json\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Configure logging to file app.log\n",
        "logging.basicConfig(\n",
        "    filename=\"app.log\",\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        ")\n",
        "\n",
        "\n",
        "# === Globals ===\n",
        "DF = None\n",
        "X = None\n",
        "y = None\n",
        "model = None\n",
        "scaler = None\n",
        "shap_explainer = None\n",
        "lime_explainer = None\n",
        "model_comparison_df = None\n",
        "model_combo = \"Combo1\"\n",
        "\n",
        "# Global toggle for hyperparameter tuning\n",
        "ENABLE_TUNING = False\n",
        "\n",
        "# === Model Combinations ===\n",
        "combos = {\n",
        "    \"Combo1\": [RandomForestClassifier(), LogisticRegression(max_iter=1000), GradientBoostingClassifier(), ExtraTreesClassifier()],\n",
        "    \"Combo2\": [AdaBoostClassifier(), GradientBoostingClassifier(), LogisticRegression(max_iter=1000), ExtraTreesClassifier()],\n",
        "    \"Combo3\": [RandomForestClassifier(), AdaBoostClassifier(), LogisticRegression(max_iter=1000), GradientBoostingClassifier()]\n",
        "}\n",
        "\n",
        "# === GEMMA setup (optional, may fail on CPU or without HF token) ===\n",
        "gemma_pipeline = None\n",
        "try:\n",
        "    from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "    model_id = \"google/gemma-1.1-2b-it\"\n",
        "    hf_token = os.environ.get(\"HF_TOKEN\")\n",
        "    if hf_token:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=hf_token)\n",
        "        gemma_model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", torch_dtype=None, use_auth_token=hf_token)\n",
        "        gemma_pipeline = pipeline(\"text-generation\", model=gemma_model, tokenizer=tokenizer)\n",
        "    else:\n",
        "        # No token provided: do not try to load the large model\n",
        "        gemma_pipeline = None\n",
        "except Exception as e:\n",
        "    # If any import or load fails, keep pipeline None and continue. Spaces may not have resources needed.\n",
        "    gemma_pipeline = None\n",
        "\n",
        "# Utility: default PIMA URL\n",
        "DEFAULT_PIMA_URL = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "\n",
        "# === Load and Train Model ===\n",
        "def load_and_train(url):\n",
        "    global DF, X, y, model, scaler, shap_explainer, lime_explainer, model_comparison_df, model_combo\n",
        "    try:\n",
        "        columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
        "                   'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "        df = pd.read_csv(url, names=columns)\n",
        "\n",
        "        # Basic validation\n",
        "        if not all(col in df.columns for col in columns):\n",
        "            return \"Error: Missing required columns in the dataset.\"\n",
        "\n",
        "        DF = df.copy()\n",
        "        X = DF.drop('Outcome', axis=1)\n",
        "        y = DF['Outcome']\n",
        "\n",
        "        # Handle missing values\n",
        "        imputer = SimpleImputer(strategy='median')\n",
        "        X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "        # Pick models from combo\n",
        "        selected_models = combos.get(model_combo, combos[\"Combo1\"])\n",
        "        results = []\n",
        "\n",
        "        trained_models = []\n",
        "        for m in selected_models:\n",
        "            # Apply tuning if ENABLE_TUNING = True\n",
        "            if isinstance(m, LogisticRegression):\n",
        "                tuned_model = tune_model(m, {\"C\": [0.01, 0.1, 1, 10]}, X_scaled, y)\n",
        "            elif isinstance(m, RandomForestClassifier):\n",
        "                tuned_model = tune_model(m, {\"n_estimators\": [50, 100, 200]}, X_scaled, y)\n",
        "            elif isinstance(m, GradientBoostingClassifier):\n",
        "                tuned_model = tune_model(m, {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 0.2]}, X_scaled, y)\n",
        "            elif isinstance(m, SVC):\n",
        "                tuned_model = tune_model(m, {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}, X_scaled, y)\n",
        "            else:\n",
        "                tuned_model = tune_model(m, {}, X_scaled, y)  # fallback\n",
        "\n",
        "            trained_models.append(tuned_model)\n",
        "\n",
        "            # Evaluate model\n",
        "            preds = tuned_model.predict(X_scaled)\n",
        "            results.append({\n",
        "                \"Model\": type(tuned_model).__name__,\n",
        "                \"Accuracy\": round(accuracy_score(y, preds), 4),\n",
        "                \"Precision\": round(precision_score(y, preds), 4),\n",
        "                \"Recall\": round(precision_score(y, preds), 4),\n",
        "                \"F1 Score\": round(f1_score(y, preds), 4)\n",
        "            })\n",
        "\n",
        "        # Pick first model for explainability\n",
        "        model = trained_models[0]\n",
        "\n",
        "        # SHAP: only works for tree/linear models with predict_proba\n",
        "        try:\n",
        "            shap_explainer = shap.TreeExplainer(model)\n",
        "        except Exception:\n",
        "            shap_explainer = None\n",
        "\n",
        "        # LIME: always works if scaling was successful\n",
        "        try:\n",
        "            lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "                training_data=X_scaled,\n",
        "                feature_names=X.columns.tolist(),\n",
        "                class_names=[\"No\", \"Yes\"],\n",
        "                mode='classification'\n",
        "            )\n",
        "        except Exception:\n",
        "            lime_explainer = None\n",
        "\n",
        "        model_comparison_df = pd.DataFrame(results)\n",
        "        globals()['scaler'] = scaler  # persist scaler for predictions\n",
        "        return \"Dataset loaded and model trained successfully!\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error during loading or training: {str(e)}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_models():\n",
        "    return {\n",
        "        \"logreg\": LogisticRegression(max_iter=500),\n",
        "        \"rf\": RandomForestClassifier(),\n",
        "        \"gb\": GradientBoostingClassifier(),\n",
        "        \"svm\": SVC(probability=True)\n",
        "    }\n",
        "\n",
        "\n",
        "def tune_model(model, param_grid, X_train, y_train):\n",
        "    global ENABLE_TUNING\n",
        "    if ENABLE_TUNING:\n",
        "        grid = GridSearchCV(model, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
        "        grid.fit(X_train, y_train)\n",
        "        return grid.best_estimator_\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        return model\n",
        "\n",
        "\n",
        "def train_models(X_train, y_train, combo=\"Combo1\"):\n",
        "    models = get_models()\n",
        "    trained = {}\n",
        "\n",
        "    if combo == \"Combo1\":\n",
        "        trained[\"logreg\"] = tune_model(\n",
        "            models[\"logreg\"],\n",
        "            {\"C\": [0.01, 0.1, 1, 10]},\n",
        "            X_train, y_train\n",
        "        )\n",
        "        trained[\"rf\"] = tune_model(\n",
        "            models[\"rf\"],\n",
        "            {\"n_estimators\": [50, 100, 200]},\n",
        "            X_train, y_train\n",
        "        )\n",
        "\n",
        "    elif combo == \"Combo2\":\n",
        "        trained[\"rf\"] = tune_model(\n",
        "            models[\"rf\"],\n",
        "            {\"n_estimators\": [50, 100, 200]},\n",
        "            X_train, y_train\n",
        "        )\n",
        "        trained[\"gb\"] = tune_model(\n",
        "            models[\"gb\"],\n",
        "            {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 0.2]},\n",
        "            X_train, y_train\n",
        "        )\n",
        "\n",
        "    elif combo == \"Combo3\":\n",
        "        trained[\"logreg\"] = tune_model(\n",
        "            models[\"logreg\"],\n",
        "            {\"C\": [0.01, 0.1, 1, 10]},\n",
        "            X_train, y_train\n",
        "        )\n",
        "        trained[\"svm\"] = tune_model(\n",
        "            models[\"svm\"],\n",
        "            {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]},\n",
        "            X_train, y_train\n",
        "        )\n",
        "\n",
        "    return trained\n",
        "def toggle_tuning(enable):\n",
        "    global ENABLE_TUNING\n",
        "    ENABLE_TUNING = enable\n",
        "    return f\"Tuning is now {'ENABLED' if enable else 'DISABLED'} for all combinations.\"\n",
        "\n",
        "def load_and_train_from_df(dataframe):\n",
        "    global df, X, y, model, scaler, shap_explainer, lime_explainer, model_comparison_df\n",
        "    try:\n",
        "        df = dataframe.copy()\n",
        "\n",
        "        # Split features and target\n",
        "        X = df.drop('Outcome', axis=1)\n",
        "        y = df['Outcome']\n",
        "\n",
        "        # Handle missing values\n",
        "        imputer = SimpleImputer(strategy='median')\n",
        "        X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "        # Standardize\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "        # Select model combo\n",
        "        selected_models = combos.get(model_combo, combos[\"Combo1\"])\n",
        "        results = []\n",
        "\n",
        "        trained_models = []\n",
        "        for m in selected_models:\n",
        "            # Apply tuning if ENABLE_TUNING = True\n",
        "            if isinstance(m, LogisticRegression):\n",
        "                tuned_model = tune_model(m, {\"C\": [0.01, 0.1, 1, 10]}, X_scaled, y)\n",
        "            elif isinstance(m, RandomForestClassifier):\n",
        "                tuned_model = tune_model(m, {\"n_estimators\": [50, 100, 200]}, X_scaled, y)\n",
        "            elif isinstance(m, GradientBoostingClassifier):\n",
        "                tuned_model = tune_model(m, {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 0.2]}, X_scaled, y)\n",
        "            elif isinstance(m, SVC):\n",
        "                tuned_model = tune_model(m, {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}, X_scaled, y)\n",
        "            else:\n",
        "                tuned_model = tune_model(m, {}, X_scaled, y)  # fallback, no tuning\n",
        "\n",
        "            trained_models.append(tuned_model)\n",
        "\n",
        "            preds = tuned_model.predict(X_scaled)\n",
        "            results.append({\n",
        "                \"Model\": type(tuned_model).__name__,\n",
        "                \"Accuracy\": round(accuracy_score(y, preds), 4),\n",
        "                \"Precision\": round(precision_score(y, preds), 4),\n",
        "                \"Recall\": round(recall_score(y, preds), 4),\n",
        "                \"F1 Score\": round(f1_score(y, preds), 4)\n",
        "            })\n",
        "\n",
        "        # Pick first model as default for explainability\n",
        "        model = trained_models[0]\n",
        "\n",
        "        # SHAP + LIME\n",
        "        shap_explainer = shap.TreeExplainer(model) if hasattr(model, \"predict_proba\") else None\n",
        "        lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "            training_data=X_scaled,\n",
        "            feature_names=X.columns.tolist(),\n",
        "            class_names=[\"No\", \"Yes\"],\n",
        "            mode='classification'\n",
        "        )\n",
        "\n",
        "        model_comparison_df = pd.DataFrame(results)\n",
        "        return \"Dataset loaded and model trained successfully!\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error during loading or training: {str(e)}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# === Upload Dataset ===\n",
        "def upload_dataset(file=None, url=None):\n",
        "    global df\n",
        "    if file is not None:\n",
        "        # Read file with headers assumed present\n",
        "        df = pd.read_csv(file.name)  # <-- reads header row\n",
        "        # Now check columns and proceed to train\n",
        "        columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
        "                   'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "        # Validate columns exist\n",
        "        if not all(col in df.columns for col in columns):\n",
        "            return \"Error: Uploaded dataset missing required columns.\", None\n",
        "\n",
        "        # Call train on the dataframe directly\n",
        "        # Since load_and_train expects URL, refactor it to accept df\n",
        "        return load_and_train_from_df(df)\n",
        "    elif url is not None:\n",
        "        return load_and_train(url)\n",
        "    else:\n",
        "        return \"No file or URL provided.\", None\n",
        "\n",
        "\n",
        "# === admin login function===\n",
        "def admin_login(username, password):\n",
        "    # Simple demo credentials (change for production)\n",
        "    if username == \"Amos\" and password == \"Kenya2025\":\n",
        "        return gr.update(visible=True), gr.update(visible=False), True\n",
        "    else:\n",
        "        return gr.update(visible=False), gr.update(visible=True), False\n",
        "\n",
        "# === Imputation Method ===\n",
        "def choose_imputation_method(method):\n",
        "    global X\n",
        "    if X is None:\n",
        "        return \"No dataset loaded.\"\n",
        "    if method == \"Median\":\n",
        "        imputer = SimpleImputer(strategy='median')\n",
        "    elif method == \"KNN\":\n",
        "        imputer = KNNImputer()\n",
        "    else:\n",
        "        return \"Invalid method selected.\"\n",
        "\n",
        "    X_imputed = imputer.fit_transform(X)\n",
        "    # update global X to imputed values\n",
        "    globals()['X'] = pd.DataFrame(X_imputed, columns=X.columns)\n",
        "    return \"Imputation method applied successfully!\"\n",
        "\n",
        "# Outlier Detection using Z-score or IQR\n",
        "def handle_outliers(method):\n",
        "    global DF\n",
        "    if DF is None or DF.empty:\n",
        "        return \"Dataset is empty\"\n",
        "\n",
        "    df_cleaned = DF.copy()\n",
        "    numeric_cols = df_cleaned.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if \"Outcome\" in numeric_cols:\n",
        "        numeric_cols.remove(\"Outcome\")\n",
        "\n",
        "    if method == \"Z-score\":\n",
        "        z_scores = np.abs((df_cleaned[numeric_cols] - df_cleaned[numeric_cols].mean()) / df_cleaned[numeric_cols].std())\n",
        "        df_cleaned = df_cleaned[(z_scores < 3).all(axis=1)]\n",
        "    elif method == \"IQR\":\n",
        "        Q1 = df_cleaned[numeric_cols].quantile(0.25)\n",
        "        Q3 = df_cleaned[numeric_cols].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        mask = ~((df_cleaned[numeric_cols] < (Q1 - 1.5 * IQR)) | (df_cleaned[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
        "        df_cleaned = df_cleaned[mask]\n",
        "    else:\n",
        "        return \"Invalid method selected\"\n",
        "\n",
        "    DF = df_cleaned.copy()\n",
        "    return f\"Outliers handled using {method}. Remaining rows: {len(DF)}\"\n",
        "\n",
        "# VIF Calculation\n",
        "def calculate_vif():\n",
        "    global DF\n",
        "    if DF is None or DF.empty:\n",
        "        return pd.DataFrame(columns=[\"Feature\", \"VIF\"])\n",
        "\n",
        "    X_vif = DF.drop(columns=[\"Outcome\"])\n",
        "    X_scaled = StandardScaler().fit_transform(X_vif)\n",
        "\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Feature\"] = X_vif.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "# Feature Importance\n",
        "def feature_importance_and_correlation():\n",
        "    global DF\n",
        "    if DF is None or DF.empty:\n",
        "        return None, None\n",
        "\n",
        "    data = DF.copy()\n",
        "    X_local = data.drop(columns=[\"Outcome\"])\n",
        "    y_local = data[\"Outcome\"]\n",
        "\n",
        "    model_local = RandomForestClassifier()\n",
        "    model_local.fit(X_local, y_local)\n",
        "    importance = pd.DataFrame({'Feature': X_local.columns, 'Importance': model_local.feature_importances_})\n",
        "\n",
        "    # Feature importance plot\n",
        "    fig1, ax1 = plt.subplots()\n",
        "    importance.sort_values(by=\"Importance\", ascending=True).plot.barh(x=\"Feature\", y=\"Importance\", ax=ax1)\n",
        "    ax1.set_title(\"Feature Importance\")\n",
        "\n",
        "    # Correlation plot\n",
        "    fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
        "    sns.heatmap(data.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=ax2)\n",
        "    ax2.set_title(\"Correlation Matrix\")\n",
        "\n",
        "    return fig1, fig2\n",
        "\n",
        "# === Model Evaluation ===\n",
        "def evaluate_model(combo, test_size=0.2, random_state=42):\n",
        "    global X, y\n",
        "    if X is None or y is None:\n",
        "        return pd.DataFrame(), None, None, None, None\n",
        "\n",
        "    selected_models = combos.get(combo, combos[\"Combo1\"])\n",
        "    results = []\n",
        "    auc_results = []\n",
        "\n",
        "    X_vals = X.values if hasattr(X, 'values') else X\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_vals, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "\n",
        "    # --- ROC Plot (Test set) ---\n",
        "    fig_roc, ax_roc = plt.subplots()\n",
        "\n",
        "    # --- Confusion Matrices (Test set) ---\n",
        "    n_models = len(selected_models)\n",
        "    n_cols = 2\n",
        "    n_rows = (n_models + 1) // n_cols\n",
        "    fig_cm, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 5 * n_rows))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, m in enumerate(selected_models):\n",
        "        m.fit(X_train, y_train)\n",
        "\n",
        "        # Train & test preds\n",
        "        train_preds = m.predict(X_train)\n",
        "        test_preds = m.predict(X_test)\n",
        "\n",
        "        # Probabilities for AUC\n",
        "        proba_train = m.predict_proba(X_train)[:, 1] if hasattr(m, \"predict_proba\") else None\n",
        "        proba_test = m.predict_proba(X_test)[:, 1] if hasattr(m, \"predict_proba\") else None\n",
        "\n",
        "        # Metrics\n",
        "        results.append({\n",
        "            \"Model\": type(m).__name__,\n",
        "            \"Train Accuracy\": round(accuracy_score(y_train, train_preds), 4),\n",
        "            \"Train Precision\": round(precision_score(y_train, train_preds), 4),\n",
        "            \"Train Recall\": round(recall_score(y_train, train_preds), 4),\n",
        "            \"Train F1\": round(f1_score(y_train, train_preds), 4),\n",
        "            \"Test Accuracy\": round(accuracy_score(y_test, test_preds), 4),\n",
        "            \"Test Precision\": round(precision_score(y_test, test_preds), 4),\n",
        "            \"Test Recall\": round(recall_score(y_test, test_preds), 4),\n",
        "            \"Test F1\": round(f1_score(y_test, test_preds), 4),\n",
        "        })\n",
        "\n",
        "        # AUC values\n",
        "        if proba_train is not None:\n",
        "            auc_train = auc(*roc_curve(y_train, proba_train)[:2])\n",
        "            auc_test = auc(*roc_curve(y_test, proba_test)[:2])\n",
        "            auc_results.append((type(m).__name__, auc_train, auc_test))\n",
        "\n",
        "            # Plot ROC for test\n",
        "            fpr, tpr, _ = roc_curve(y_test, proba_test)\n",
        "            ax_roc.plot(fpr, tpr, label=f\"{type(m).__name__} (AUC={auc_test:.2f})\")\n",
        "\n",
        "        # Confusion matrix (test)\n",
        "        cm = confusion_matrix(y_test, test_preds)\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "                    xticklabels=[\"No\", \"Yes\"], yticklabels=[\"No\", \"Yes\"], ax=axes[i])\n",
        "        axes[i].set_title(f\"{type(m).__name__}\")\n",
        "        axes[i].set_xlabel(\"Predicted\")\n",
        "        axes[i].set_ylabel(\"Actual\")\n",
        "\n",
        "    # Remove unused subplots\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        fig_cm.delaxes(axes[j])\n",
        "\n",
        "    # Finalize ROC\n",
        "    ax_roc.plot([0, 1], [0, 1], 'k--')\n",
        "    ax_roc.set_title(\"Test ROC Curves\")\n",
        "    ax_roc.set_xlabel(\"False Positive Rate\")\n",
        "    ax_roc.set_ylabel(\"True Positive Rate\")\n",
        "    ax_roc.legend(loc=\"lower right\")\n",
        "\n",
        "    # --- AUC Bar Plot ---\n",
        "    fig_auc, ax_auc = plt.subplots()\n",
        "    models = [r[0] for r in auc_results]\n",
        "    train_aucs = [r[1] for r in auc_results]\n",
        "    test_aucs = [r[2] for r in auc_results]\n",
        "    x = range(len(models))\n",
        "    ax_auc.bar([i - 0.2 for i in x], train_aucs, width=0.4, label=\"Train AUC\")\n",
        "    ax_auc.bar([i + 0.2 for i in x], test_aucs, width=0.4, label=\"Test AUC\")\n",
        "    ax_auc.set_xticks(x)\n",
        "    ax_auc.set_xticklabels(models, rotation=45)\n",
        "    ax_auc.set_ylim(0.0, 1.0)\n",
        "    ax_auc.set_title(\"Train vs Test AUC Comparison\")\n",
        "    ax_auc.set_ylabel(\"AUC Score\")\n",
        "    ax_auc.legend()\n",
        "\n",
        "    return pd.DataFrame(results), fig_roc, fig_cm, fig_auc\n",
        "\n",
        "\n",
        "# Prediction\n",
        "def predict_diabetes(p, g, bp, st, i, bmi, dpf, age):\n",
        "    global model, scaler\n",
        "\n",
        "    if model is None or scaler is None:\n",
        "        return \"Model not loaded or trained yet.\"\n",
        "\n",
        "    input_data = np.array([[p, g, bp, st, i, bmi, dpf, age]])\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "    prediction = model.predict(input_scaled)[0]\n",
        "    return \"Positive (Diabetes)\" if prediction == 1 else \"Negative (No Diabetes)\"\n",
        "\n",
        "# LIME explanation\n",
        "def explain_with_lime(p, g, bp, st, i, bmi, dpf, age):\n",
        "    global lime_explainer, scaler, model\n",
        "\n",
        "    if lime_explainer is None or model is None or scaler is None:\n",
        "        return \"<b>LIME components are not initialized.</b>\"\n",
        "\n",
        "    input_array = np.array([[p, g, bp, st, i, bmi, dpf, age]])\n",
        "    input_scaled = scaler.transform(input_array)\n",
        "\n",
        "    lime_exp = lime_explainer.explain_instance(input_scaled[0], model.predict_proba, num_features=5)\n",
        "    html_exp = lime_exp.as_list()\n",
        "\n",
        "    table_html = \"<h4>LIME Explanation</h4><table border='1'><tr><th>Feature</th><th>Weight</th></tr>\"\n",
        "    for feature, weight in html_exp:\n",
        "        color = \"#90ee90\" if weight < 0 else \"#f08080\"\n",
        "        table_html += f\"<tr style='background:{color}'><td>{feature}</td><td>{round(weight, 4)}</td></tr>\"\n",
        "    table_html += \"</table>\"\n",
        "    return table_html\n",
        "\n",
        "# SHAP explanation\n",
        "def explain_with_shap(p, g, bp, st, i, bmi, dpf, age):\n",
        "    global shap_explainer, X\n",
        "\n",
        "    if shap_explainer is None or X is None:\n",
        "        return \"<b>SHAP explainer or dataset not initialized.</b>\"\n",
        "\n",
        "    try:\n",
        "        shap_values = shap_explainer.shap_values(X)\n",
        "    except Exception:\n",
        "        return \"<b>SHAP computation failed for this model.</b>\"\n",
        "\n",
        "    mean_abs_shap = np.abs(shap_values[1]).mean(axis=0).flatten()\n",
        "    mean_raw_shap = np.array(shap_values[1]).mean(axis=0).flatten()\n",
        "\n",
        "    directions = [\"increases risk\" if val > 0 else \"decreases risk\" if val < 0 else \"neutral\"\n",
        "                  for val in mean_raw_shap]\n",
        "\n",
        "    feature_impact = list(zip(X.columns.tolist(), mean_abs_shap, directions))\n",
        "    feature_impact.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    html = \"<h4>Top Features by Mean SHAP Impact</h4><table border='1' style='border-collapse:collapse;'>\"\n",
        "    html += \"<tr><th>Rank</th><th>Feature</th><th>Mean SHAP Value</th><th>Effect</th></tr>\"\n",
        "    for i_, (feature, impact, direction) in enumerate(feature_impact, start=1):\n",
        "        color = \"#90ee90\" if \"decreases\" in direction else \"#f08080\" if \"increases\" in direction else \"#ffffff\"\n",
        "        html += f\"<tr style='background-color:{color}'><td>{i_}</td><td>{feature}</td><td>{impact:.4f}</td><td>{direction}</td></tr>\"\n",
        "    html += \"</table>\"\n",
        "\n",
        "    return html\n",
        "\n",
        "# GEMMA explanation (uses pipeline if available)\n",
        "def explain_with_gemma(g, bmi, i, age, p):\n",
        "    prompt = f\"\"\"Explain how the following clinical features relate to diabetes prediction:\\n    - Glucose: {g}\\n    - BMI: {bmi}\\n    - Insulin: {i}\\n    - Age: {age}\\n    - Pregnancies: {p}\\n    \"\"\"\n",
        "    if gemma_pipeline is None:\n",
        "        return \"GEMMA model unavailable in this environment Use GPU.\"\n",
        "    try:\n",
        "        response = gemma_pipeline(prompt, max_new_tokens=150, do_sample=True)[0]['generated_text']\n",
        "        return response[len(prompt):].strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error generating GEMMA response: {str(e)}\"\n",
        "\n",
        "# Download report\n",
        "def download_report(name, pid, date, p, g, bp, st, i, bmi, dpf, age, gemma_output, clinician_comments):\n",
        "    global model, scaler\n",
        "\n",
        "    if model is None or scaler is None:\n",
        "        logging.error(\"Report generation attempted before model was trained.\")\n",
        "        return None\n",
        "\n",
        "    encounter_ref = str(uuid.uuid4())[:8].upper()\n",
        "    input_data = np.array([[p, g, bp, st, i, bmi, dpf, age]])\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "    prediction = model.predict(input_scaled)[0]\n",
        "    result = \"Positive (Diabetes)\" if prediction == 1 else \"Negative (No Diabetes)\"\n",
        "\n",
        "    report_text = f\"\"\"Diabetes Prediction Report\\n\\nVisit Encounter Reference : {encounter_ref}\\nDate : {date}\\n\\nPatient: {name} (ID: {pid})\\n\\nPregnancies: {p}\\nGlucose: {g}\\nBlood Pressure: {bp}\\nSkinThickness: {st}\\nInsulin: {i}\\nBMI: {bmi}\\nDPF: {dpf}\\nAge: {age}\\n\\nResult: {result}\\n\\nGEMMA Explanation:\\n{gemma_output}\\n\\nClinician's Notes:\\n{clinician_comments}\\n\"\"\"\n",
        "\n",
        "    # Log the report event\n",
        "    logging.info(\n",
        "        f\"Report generated | Encounter: {encounter_ref} | Patient ID: {pid} | Result: {result}\"\n",
        "    )\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.txt') as tmp_file:\n",
        "        tmp_file.write(report_text)\n",
        "        return tmp_file.name\n",
        "  # Log admin viwe function the report event\n",
        "def view_logs():\n",
        "    try:\n",
        "        with open(\"app.log\", \"r\") as f:\n",
        "            logs = f.read()\n",
        "        return logs if logs else \"Log file is empty.\"\n",
        "    except FileNotFoundError:\n",
        "        return \"No logs found yet.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error reading logs: {e}\"\n",
        "\n",
        "def compute_sus_score(responses):\n",
        "    \"\"\"\n",
        "    responses: list of 10 ints (1–5). SUS scoring:\n",
        "    - Odd items (1,3,5,7,9): score = response - 1\n",
        "    - Even items (2,4,6,8,10): score = 5 - response\n",
        "    \"\"\"\n",
        "    if not responses or len(responses) != 10:\n",
        "        return None\n",
        "    score_sum = 0\n",
        "    for idx, resp in enumerate(responses, start=1):\n",
        "        try:\n",
        "            resp = int(resp)\n",
        "        except Exception:\n",
        "            return None\n",
        "        if idx % 2 == 1:\n",
        "            score_sum += (resp - 1)\n",
        "        else:\n",
        "            score_sum += (5 - resp)\n",
        "    return round(score_sum * 2.5, 2)\n",
        "\n",
        "\n",
        "def save_survey_to_log(respondent_name, respondent_email, sus_answers,\n",
        "                       likert_answers, open_q1, open_q2):\n",
        "    \"\"\"\n",
        "    Save feedback into feedback.log (JSON lines).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        record = {\n",
        "            \"id\": str(uuid.uuid4()),\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"respondent_name\": respondent_name.strip() if respondent_name else \"\",\n",
        "            \"respondent_email\": respondent_email.strip() if respondent_email else \"\",\n",
        "            \"sus_answers\": [int(x) for x in sus_answers],\n",
        "            \"sus_score\": compute_sus_score(sus_answers),\n",
        "            \"likert_answers\": {\n",
        "                \"easy_to_navigate\": int(likert_answers[0]),\n",
        "                \"shap_lime_clear\": int(likert_answers[1]),\n",
        "                \"gemma_increased_trust\": int(likert_answers[2]),\n",
        "                \"useful_for_care_decisions\": int(likert_answers[3]),\n",
        "                \"overall_trust\": int(likert_answers[4]),\n",
        "            },\n",
        "            \"open_qs\": {\n",
        "                \"most_helpful\": open_q1.strip() if open_q1 else \"\",\n",
        "                \"how_improve_explanations\": open_q2.strip() if open_q2 else \"\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        with open(\"feedback.log\", \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "        logging.info(f\"Saved survey response | id: {record['id']} | SUS: {record['sus_score']}\")\n",
        "        return True, record[\"sus_score\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to save survey: {e}\")\n",
        "        return False, str(e)\n",
        "\n",
        "\n",
        "def load_feedback_for_admin():\n",
        "    \"\"\"\n",
        "    Read feedback.log into DataFrame.\n",
        "    Returns empty DataFrame if no feedback exists.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    if not os.path.exists(\"feedback.log\"):\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        with open(\"feedback.log\", \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                try:\n",
        "                    obj = json.loads(line)\n",
        "                    flat = {\n",
        "                        \"id\": obj.get(\"id\"),\n",
        "                        \"timestamp\": obj.get(\"timestamp\"),\n",
        "                        \"name\": obj.get(\"respondent_name\"),\n",
        "                        \"email\": obj.get(\"respondent_email\"),\n",
        "                        \"sus_score\": obj.get(\"sus_score\"),\n",
        "                    }\n",
        "                    # Add individual SUS answers\n",
        "                    sus = obj.get(\"sus_answers\", [])\n",
        "                    for i in range(10):\n",
        "                        flat[f\"sus_q{i+1}\"] = sus[i] if i < len(sus) else None\n",
        "\n",
        "                    # Add likert answers\n",
        "                    lik = obj.get(\"likert_answers\", {})\n",
        "                    for key in [\"easy_to_navigate\", \"shap_lime_clear\", \"gemma_increased_trust\",\n",
        "                                \"useful_for_care_decisions\", \"overall_trust\"]:\n",
        "                        flat[key] = lik.get(key)\n",
        "\n",
        "                    # Add open-ended responses\n",
        "                    open_qs = obj.get(\"open_qs\", {})\n",
        "                    flat[\"most_helpful\"] = open_qs.get(\"most_helpful\", \"\")\n",
        "                    flat[\"how_improve_explanations\"] = open_qs.get(\"how_improve_explanations\", \"\")\n",
        "\n",
        "                    rows.append(flat)\n",
        "                except json.JSONDecodeError:\n",
        "                    logging.warning(\"Skipped malformed line in feedback.log\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading feedback: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# === Build Gradio UI ===\n",
        "\n",
        "today_str = datetime.today().strftime('%Y-%m-%d')\n",
        "\n",
        "# === Functions used in callbacks ===\n",
        "# Define all your functions here, e.g., predict_diabetes, explain_with_shap, explain_with_lime, explain_with_gemma,\n",
        "# download_report, admin_login, load_and_train, upload_dataset, feature_importance_and_correlation,\n",
        "# calculate_vif, choose_imputation_method, handle_outliers, evaluate_model, view_logs\n",
        "\n",
        "# === Build Gradio UI ===\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    # === Help / Survey Buttons ===\n",
        "    with gr.Row():\n",
        "        help_btn = gr.Button(\" Help / Send Message\", variant=\"secondary\")\n",
        "        survey_btn = gr.Button(\" Take Survey\", variant=\"primary\")\n",
        "\n",
        "    help_section = gr.Column(visible=False)\n",
        "    survey_section = gr.Column(visible=False)\n",
        "\n",
        "    # -------------------- HELP SECTION --------------------\n",
        "    with help_section:\n",
        "        with gr.Tab(\"Quick-start Guide\"):\n",
        "            with gr.Accordion(\"Quick-start Guide\", open=False):\n",
        "                gr.Markdown(\"\"\"\n",
        "                **Step 1:** Enter patient details (Name, ID, Date).\n",
        "                **Step 2:** Fill in the clinical measurements (Pregnancies, Glucose, etc.).\n",
        "                **Step 3:** Click **Predict** to get a result.\n",
        "                **Step 4:** Use **SHAP** or **LIME** tabs to understand the prediction.\n",
        "                **Step 5:** Click **Ask Gemma** to get a Gemma Explanation.\n",
        "                **Step 6:** Download a report if needed.\n",
        "                \"\"\")\n",
        "\n",
        "        with gr.Tab(\"FAQ\"):\n",
        "            with gr.Accordion(\"What dataset does this app use?\", open=False):\n",
        "                gr.Markdown(\"It uses the **Pima Indians Diabetes Dataset** from Kaggle/UCI.\")\n",
        "            with gr.Accordion(\"Can I use my own dataset?\", open=False):\n",
        "                gr.Markdown(\"Yes! Log in as admin and upload your dataset in CSV format.\")\n",
        "            with gr.Accordion(\"How do I interpret SHAP/LIME outputs?\", open=False):\n",
        "                gr.Markdown(\"Green values reduce diabetes risk, red values increase it.\")\n",
        "\n",
        "        with gr.Tab(\"Contact Us\"):\n",
        "            name_cf = gr.Textbox(label=\"Your Name\")\n",
        "            email_cf = gr.Textbox(label=\"Your Email\")\n",
        "            msg_cf = gr.Textbox(label=\"Message\", lines=4)\n",
        "\n",
        "            with gr.Row():\n",
        "                submit_cf = gr.Button(\"Submit\")\n",
        "                refresh_cf = gr.Button(\"Refresh\")\n",
        "\n",
        "            contact_status = gr.Markdown()\n",
        "\n",
        "            def save_contact(name, email, message):\n",
        "                try:\n",
        "                    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                    with open(\"contact_messages.txt\", \"a\") as f:\n",
        "                        f.write(f\"[{ts}] {name} ({email}): {message}\\n\")\n",
        "                    return \" Your message has been sent. Thank you!\"\n",
        "                except Exception as e:\n",
        "                    return f\" Failed to send message: {e}\"\n",
        "\n",
        "            submit_cf.click(save_contact, [name_cf, email_cf, msg_cf], contact_status)\n",
        "\n",
        "            def refresh_form():\n",
        "                return \"\", \"\", \"\"\n",
        "\n",
        "            refresh_cf.click(refresh_form, None, [name_cf, email_cf, msg_cf])\n",
        "\n",
        "        # Close Help button\n",
        "        close_help_btn = gr.Button(\"Close Help\", variant=\"secondary\")\n",
        "\n",
        "    # -------------------- SURVEY SECTION --------------------\n",
        "    with survey_section:\n",
        "        gr.Markdown(\"## Quick Survey — System Usability & Trust\")\n",
        "\n",
        "        survey_name = gr.Textbox(label=\"Your name (optional)\")\n",
        "        survey_email = gr.Textbox(label=\"Your email (optional)\")\n",
        "\n",
        "        # Example SUS Questions\n",
        "        sus_q1 = gr.Radio(choices=[\"1\",\"2\",\"3\",\"4\",\"5\"], label=\"SUS 1: I think I would use this system frequently.\")\n",
        "        sus_q2 = gr.Radio(choices=[\"1\",\"2\",\"3\",\"4\",\"5\"], label=\"SUS 2: I find the system unnecessarily complex.\")\n",
        "        sus_q3 = gr.Radio(choices=[\"1\",\"2\",\"3\",\"4\",\"5\"], label=\"SUS 3: I think the system is easy to use.\")\n",
        "        sus_q4 = gr.Radio(choices=[\"1\",\"2\",\"3\",\"4\",\"5\"], label=\"SUS 4: I think I would need support to use this system.\")\n",
        "        sus_q5 = gr.Radio(choices=[\"1\",\"2\",\"3\",\"4\",\"5\"], label=\"SUS 5: I find the system well integrated.\")\n",
        "        sus_q6 = gr.Radio(choices=[\"1\",\"2\",\"3\",\"4\",\"5\"], label=\"SUS 6: I think there is too much inconsistency in this system.\")\n",
        "        sus_q7 = gr.Radio(choices=[\"1\",\"2\",\"3\",\"4\",\"5\"], label=\"SUS 7: I would imagine most people would learn to use it quickly.\")\n",
        "        sus_q8 = gr.Radio(choices=[\"1\",\"2\",\"3\",\"4\",\"5\"], label=\"SUS 8: I find the system very cumbersome to use.\")\n",
        "        sus_q9 = gr.Radio(choices=[\"1\",\"2\",\"3\",\"4\",\"5\"], label=\"SUS 9: I feel very confident using the system.\")\n",
        "        sus_q10 = gr.Radio(choices=[\"1\",\"2\",\"3\",\"4\",\"5\"], label=\"SUS 10: I needed to learn a lot before I could use the system.\")\n",
        "\n",
        "        # Open-ended Questions\n",
        "        open_q1 = gr.Textbox(label=\"What do you like about the system?\", lines=3)\n",
        "        open_q2 = gr.Textbox(label=\"What can be improved?\", lines=3)\n",
        "\n",
        "        with gr.Row():\n",
        "            submit_survey_btn = gr.Button(\"Submit Survey\", variant=\"primary\")\n",
        "            clear_survey_btn = gr.Button(\"Clear Form\", variant=\"secondary\")\n",
        "\n",
        "        survey_status = gr.Markdown()\n",
        "\n",
        "        def submit_survey_click(name, email, *answers):\n",
        "            try:\n",
        "                ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                with open(\"feedback.log\", \"a\") as f:   # <--- write to feedback.log\n",
        "                    f.write(f\"[{ts}] Name: {name}, Email: {email}, Answers: {answers}\\n\")\n",
        "                return \" Thank you — your survey has been saved.\"\n",
        "            except Exception as e:\n",
        "                return f\" Error: {e}\"\n",
        "\n",
        "        submit_inputs = [\n",
        "            survey_name, survey_email,\n",
        "            sus_q1, sus_q2, sus_q3, sus_q4, sus_q5,\n",
        "            sus_q6, sus_q7, sus_q8, sus_q9, sus_q10,\n",
        "            open_q1, open_q2\n",
        "        ]\n",
        "\n",
        "        submit_survey_btn.click(submit_survey_click, submit_inputs, survey_status)\n",
        "\n",
        "        def clear_survey():\n",
        "            return \"\", \"\", \"3\",\"3\",\"3\",\"3\",\"3\",\"3\",\"3\",\"3\",\"3\",\"3\",\"\", \"\"\n",
        "\n",
        "        clear_survey_btn.click(clear_survey, None, submit_inputs)\n",
        "\n",
        "        # Close Survey button\n",
        "        close_survey_btn = gr.Button(\"Close Survey\", variant=\"secondary\")\n",
        "\n",
        "    # -------------------- TOGGLE LOGIC --------------------\n",
        "    help_btn.click(\n",
        "        lambda: (gr.update(visible=True), gr.update(visible=False)),\n",
        "        None, [help_section, survey_section]\n",
        "    )\n",
        "\n",
        "    close_help_btn.click(lambda: gr.update(visible=False), None, help_section)\n",
        "\n",
        "    survey_btn.click(\n",
        "        lambda: (gr.update(visible=False), gr.update(visible=True)),\n",
        "        None, [help_section, survey_section]\n",
        "    )\n",
        "\n",
        "    close_survey_btn.click(lambda: gr.update(visible=False), None, survey_section)\n",
        "\n",
        "\n",
        "    # === User Interface ===\n",
        "    gr.Markdown(\"## Diabetes Prediction System (User Interface)\")\n",
        "\n",
        "    with gr.Group():\n",
        "        name = gr.Textbox(label=\"Patient Name\")\n",
        "        pid = gr.Textbox(label=\"Patient ID\")\n",
        "        date = gr.Textbox(label=\"Date (YYYY-MM-DD)\", value=today_str)\n",
        "        p = gr.Number(label=\"Pregnancies (0–20)\", value=0, minimum=0, maximum=20)\n",
        "        g = gr.Number(label=\"Glucose (0–200 mg/dL)\", value=0, minimum=0, maximum=200)\n",
        "        bp = gr.Number(label=\"Blood Pressure (0–150 mm Hg)\", value=0, minimum=0, maximum=150)\n",
        "        st = gr.Number(label=\"Skin Thickness (0–100 mm)\", value=0, minimum=0, maximum=100)\n",
        "        i = gr.Number(label=\"Insulin (0–900 mu U/ml)\", value=0, minimum=0, maximum=900)\n",
        "        bmi = gr.Number(label=\"BMI (0–70)\", value=0.0, minimum=0, maximum=70)\n",
        "        dpf = gr.Number(label=\"DPF (0.0–2.5)\", value=0.0, minimum=0.0, maximum=2.5)\n",
        "        age = gr.Number(label=\"Age (1–120 years)\", value=0, minimum=1, maximum=120)\n",
        "\n",
        "        with gr.Tabs():\n",
        "            with gr.TabItem(\"1 Predict\"):\n",
        "                out_pred = gr.Textbox(label=\"Prediction\")\n",
        "                gr.Button(\"Predict\").click(predict_diabetes, [p, g, bp, st, i, bmi, dpf, age], out_pred)\n",
        "\n",
        "            with gr.TabItem(\"2 SHAP\"):\n",
        "                out_shap = gr.HTML()\n",
        "                gr.Button(\"Explain SHAP\").click(explain_with_shap, [p, g, bp, st, i, bmi, dpf, age], out_shap)\n",
        "\n",
        "            with gr.TabItem(\"3 LIME\"):\n",
        "                out_lime = gr.HTML()\n",
        "                gr.Button(\"Explain LIME\").click(explain_with_lime, [p, g, bp, st, i, bmi, dpf, age], out_lime)\n",
        "\n",
        "            with gr.TabItem(\"4 GEMMA\"):\n",
        "                out_gemma = gr.Textbox()\n",
        "                gr.Button(\"Ask GEMMA\").click(explain_with_gemma, [g, bmi, i, age, p], out_gemma)\n",
        "\n",
        "            with gr.TabItem(\"5 Report\"):\n",
        "                clinician_comments = gr.Textbox(label=\"Clinician Comments\", lines=4, placeholder=\"Enter any relevant notes...\")\n",
        "                report = gr.File()\n",
        "                gr.Button(\"Download Report\").click(\n",
        "                    download_report,\n",
        "                    inputs=[name, pid, date, p, g, bp, st, i, bmi, dpf, age, out_gemma, clinician_comments],\n",
        "                    outputs=report\n",
        "                )\n",
        "\n",
        "    # === Admin Interface ===\n",
        "    gr.Markdown(\"## Admin Login\")\n",
        "    admin_user = gr.Textbox(label=\"Username\")\n",
        "    admin_pass = gr.Textbox(label=\"Password\", type=\"password\")\n",
        "    login_btn = gr.Button(\"Login\")\n",
        "    login_fail = gr.Markdown(\" Invalid credentials. Try again.\", visible=False)\n",
        "\n",
        "    # Admin Panel (hidden until login)\n",
        "    admin_panel = gr.Group(visible=False)\n",
        "    with admin_panel:\n",
        "        gr.Markdown(\"## Admin Interface\")\n",
        "\n",
        "        with gr.Tab(\"Data Management\"):\n",
        "            gr.Markdown(\"### Load Dataset\")\n",
        "            load_output = gr.Textbox(label=\"Load Status\", interactive=False)\n",
        "            data_preview = gr.Dataframe(label=\"Loaded Dataset\", interactive=False)\n",
        "\n",
        "            dataset_url = DEFAULT_PIMA_URL\n",
        "            load_url_button = gr.Button(\"Load Default Dataset from URL\")\n",
        "            load_url_button.click(fn=lambda: load_and_train(dataset_url), inputs=[], outputs=[load_output])\n",
        "\n",
        "            file_upload = gr.File(label=\"Upload Your Own Dataset (CSV)\")\n",
        "            load_file_button = gr.Button(\"Upload from File\")\n",
        "            load_file_button.click(fn=upload_dataset, inputs=[file_upload, gr.Textbox(visible=False)], outputs=[load_output])\n",
        "\n",
        "        with gr.Tab(\"EDA\"):\n",
        "            gr.Markdown(\"### Feature Importance & Correlation Matrix\")\n",
        "            eda_btn = gr.Button(\"Run EDA\")\n",
        "            feat_imp_plot = gr.Plot(label=\"Feature Importance\")\n",
        "            corr_plot = gr.Plot(label=\"Correlation Matrix\")\n",
        "            eda_btn.click(fn=feature_importance_and_correlation, inputs=[], outputs=[feat_imp_plot, corr_plot])\n",
        "\n",
        "            gr.Markdown(\"### Variance Inflation Factor (VIF)\")\n",
        "            vif_btn = gr.Button(\"Calculate VIF\")\n",
        "            vif_output = gr.Dataframe(label=\"VIF Results\", interactive=False)\n",
        "            vif_btn.click(fn=calculate_vif, inputs=[], outputs=[vif_output])\n",
        "\n",
        "        with gr.Tab(\"Data Preprocessing\"):\n",
        "            gr.Markdown(\"### Imputation Method\")\n",
        "            method = gr.Radio(choices=[\"Median\", \"KNN\"], label=\"Select Imputation Method\")\n",
        "            apply_button = gr.Button(\"Apply\")\n",
        "            imputation_output = gr.Textbox(label=\"Imputation Status\", interactive=False)\n",
        "            apply_button.click(choose_imputation_method, [method], imputation_output)\n",
        "\n",
        "            gr.Markdown(\"### Outlier Handling\")\n",
        "            outlier_method = gr.Radio(choices=[\"Z-score\", \"IQR\"], label=\"Select Outlier Handling Method\")\n",
        "            outlier_status = gr.Textbox(label=\"Outlier Handling Status\", interactive=False)\n",
        "            gr.Button(\"Handle Outliers\").click(handle_outliers, inputs=[outlier_method], outputs=[outlier_status])\n",
        "\n",
        "        with gr.Tab(\"Hyperparameter Tuning\"):\n",
        "            enable_tuning = gr.Checkbox(label=\"Enable Hyperparameter Tuning (all combos)\", value=ENABLE_TUNING)\n",
        "            tuning_status = gr.Textbox(label=\"Tuning Status\", interactive=False)\n",
        "\n",
        "            enable_tuning.change(\n",
        "                fn=toggle_tuning,\n",
        "                inputs=[enable_tuning],\n",
        "                outputs=[tuning_status]\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Model Combo Selection\"):\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ### Model Combination Options\n",
        "                **Combo 1**: Random Forest + Logistic Regression + Gradient Boosting + Extra Trees\n",
        "                **Combo 2**: AdaBoost + Gradient Boosting + Logistic Regression + Extra Trees\n",
        "                **Combo 3**: Random Forest + AdaBoost + Logistic Regression + Gradient Boosting\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "            # --- Dropdown for model combo ---\n",
        "            model_combo_dropdown = gr.Dropdown(\n",
        "                choices=[\"Combo1\", \"Combo2\", \"Combo3\"],\n",
        "                value=\"Combo1\",\n",
        "                label=\"Select Model Combination\"\n",
        "            )\n",
        "\n",
        "            # --- Evaluate button ---\n",
        "            evaluate_btn = gr.Button(\"Evaluate Models\")\n",
        "\n",
        "            # --- Outputs ---\n",
        "            metrics_output = gr.Dataframe(label=\"Training vs Test Performance\")\n",
        "            roc_plot = gr.Plot(label=\"ROC Curves (Test Set)\")\n",
        "            cm_plot = gr.Plot(label=\"Confusion Matrices (Test Set)\")\n",
        "            auc_plot = gr.Plot(label=\"Train vs Test AUC Comparison\")\n",
        "\n",
        "            # --- Button wiring ---\n",
        "            evaluate_btn.click(\n",
        "                evaluate_model,\n",
        "                inputs=[model_combo_dropdown],\n",
        "                outputs=[metrics_output, roc_plot, cm_plot, auc_plot]\n",
        "            )\n",
        "\n",
        "            # Legend / explanation text\n",
        "            legend_text = gr.Markdown(\n",
        "                \"\"\"\n",
        "                ### Legend\n",
        "                **AUC (Area Under the ROC Curve)**\n",
        "                - 0.5 = random guessing\n",
        "                - 0.7–0.8 = acceptable discrimination\n",
        "                - 0.8–0.9 = very good discrimination\n",
        "                - >0.9 = excellent discrimination\n",
        "                **Training Metrics**\n",
        "                - Show how well the model fits the data it has already seen.\n",
        "                - High training scores but much lower test scores → **Overfitting**.\n",
        "                - Both train & test low → **Underfitting**.\n",
        "                **Test Metrics (most important)**\n",
        "                - Reflect how the model performs on unseen data (generalization).\n",
        "                - ROC curve → ability to distinguish classes when deployed.\n",
        "                - Confusion matrix → shows real-world prediction errors (false positives/negatives).\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"System Logs\"):\n",
        "            gr.Markdown(\"### Application Logs\")\n",
        "            log_btn = gr.Button(\"View Logs\")\n",
        "            log_output = gr.Textbox(\n",
        "                label=\"Log Output\",\n",
        "                lines=15,\n",
        "                interactive=False,\n",
        "                placeholder=\"Click 'View Logs' to display log entries...\"\n",
        "            )\n",
        "            log_btn.click(fn=view_logs, inputs=None, outputs=log_output)\n",
        "        with gr.Tab(\"Feedback\"):\n",
        "            gr.Markdown(\"### Survey Feedback (Responses saved to `feedback.log`)\")\n",
        "            load_feedback_btn = gr.Button(\"Load Feedback\")\n",
        "            refresh_feedback_btn = gr.Button(\"Refresh\")\n",
        "            export_feedback_btn = gr.Button(\"Download feedback.log\")\n",
        "            feedback_df = gr.Dataframe(label=\"Survey Responses\", interactive=False)\n",
        "            feedback_text = gr.Textbox(label=\"Raw feedback.log (first 1000 chars)\", lines=6, interactive=False)\n",
        "\n",
        "            def load_feedback():\n",
        "                df = load_feedback_for_admin()\n",
        "                try:\n",
        "                    with open(\"feedback.log\", \"r\", encoding=\"utf-8\") as f:\n",
        "                        data = f.read(1000)\n",
        "                        raw = data if data else \"No feedback logged yet.\"\n",
        "                except FileNotFoundError:\n",
        "                    raw = \"No feedback.log found.\"\n",
        "                return df, raw\n",
        "\n",
        "            load_feedback_btn.click(load_feedback, None, [feedback_df, feedback_text])\n",
        "            refresh_feedback_btn.click(load_feedback, None, [feedback_df, feedback_text])\n",
        "            export_feedback_btn.click(lambda: \"feedback.log\", None, gr.File(label=\"feedback file\"))\n",
        "\n",
        "\n",
        "    # Connect login button inside the Blocks context\n",
        "    login_btn.click(admin_login, inputs=[admin_user, admin_pass], outputs=[admin_panel, login_fail, gr.State()])\n",
        "\n",
        "# === Preload default dataset ===\n",
        "try:\n",
        "    load_and_train(DEFAULT_PIMA_URL)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# === Launch App ===\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True)\n"
      ]
    }
  ]
}